Branch: pos_spark_train

Update date: 2016-06-25 01:31

Author: Jetic Gu

# For more information on Jetic's changes, he keeps a very detailed dev log on
# his note pad. If you ask him, he'll get you a copy.

Ongoing tasks:
1. Test the glm_parser with data_prep on hadoop
    (DONE: 2016-06-23 04:52)

2. Integrate data_prep and data_pool
    (DONE: 2016-06-25 00:05)
    Thoughts:
        a). I think that the data_prep should be a part of the data_pool,
            because all it does is preparing the data.
        b). I am seeing a lot of data_pool instances, they shouldn't all be
            necessary. For sequential run, there should
            only be two, one for training and one for testing.
        c). Why is the feature generator specified in the data_pool instead of
            the learner? Is it just me or is it really ridiculous?
        d). There should be a debug switch.
    Steps:
        a). Restructure the training part of glm_parser.py, we need the train
            function to take the datapool as an argument.
            (DONE: 2016-06-24 13:49. The only problem with parallel part is that
            we need to restructure the data_pool and learner first, because it
            now takes dataPrep.loadedPath as an argument)
        b). Restructure the data_pool so that it uses data_prep to prepare the
            data.
            (DONE: 2016-06-24 15:12. Parallel tests will be done after learner
            restructure.)
        c). Restructure the learner to take the datapool as an argument.
            (DONE: 2016-06-25 00:05. Implementation has passed sequential test
            on debug.config, parallel test on standalone mode with debug.config
            (4 shards) and yarn mode with default.config(8 shards)
        d). In the end, I didn't implement the debug switch for data_pool,
            I haven't really gotten that far with data_pool. Maybe I'll do that
            when I am restructuring the learner.
        e). I shall now merge with master.

3. Restructure the learners
    (ONGOING)
    Thoughts:
        a). There should be four learners now: 1) averaged perceptron;
            2) perceptron; 3) averaged perceptron in parallel; 4) perceptron in
            parallel. But currently 3) and 4) are squeezed into one file while
            part of 3) and 4) is in 2).
        b). Functions of a specific class should make sense. Now, it's chaos.
        c). There should be a debug switch.
    Steps:
        a). Move the parallel_train part for parallel train to spark_train.py
        b). Separate the code for averaged_perceptron_parallel and
            perceptron_parallel.
        c). Unify the parameters for all learners if necessary.

4. pos_tagger should be using data_pool as main data storage device.
    (Coming)

5. pos_tagger should be using learners just like the parser.
    (Coming)

6. After all is done, merge with Kingston.
    (Coming)
